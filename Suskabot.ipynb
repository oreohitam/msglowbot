{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{"id":"95bjPcuvMy9o"},"source":["# KELOMPOK 7 (THE FASTAR)\n","# PROJEK AKHIR SUSKABOT\n","\n","NAMA ANGGOTA :\n","1. CANDRALIKA DIFA SENA\n","2. SYAFRIDHO\n","3. AULI NURRAHMAN\n","4. FEBRIA RAHMANIKA\n","5. MUHAMMAD RAMADHAN"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["IMPORT LIBRARY DAN DATASET"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# Import Libraries\n","import json\n","import nltk\n","import time\n","import random\n","import string\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import tensorflow as tf\n","import IPython.display as ipd\n","import matplotlib.pyplot as plt\n","from nltk.stem import WordNetLemmatizer\n","import tensorflow as tf \n","from keras.utils.vis_utils import plot_model\n","from sklearn.preprocessing import LabelEncoder"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting keras==2.6.0\n","  Using cached keras-2.6.0-py2.py3-none-any.whl (1.3 MB)\n","Installing collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.14.0\n","    Uninstalling keras-2.14.0:\n","      Successfully uninstalled keras-2.14.0\n","Successfully installed keras-2.6.0\n","Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-intel 2.13.0 requires keras<2.14,>=2.13.1, but you have keras 2.6.0 which is incompatible.\n","tensorflow-intel 2.13.0 requires typing-extensions<4.6.0,>=3.6.6, but you have typing-extensions 4.7.1 which is incompatible.\n"]}],"source":["pip install keras==2.6.0\n"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to\n","[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package wordnet to\n","[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n","[nltk_data] Downloading package omw-1.4 to\n","[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n","[nltk_data]   Package omw-1.4 is already up-to-date!\n"]},{"data":{"text/plain":["True"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["# Package sentence tokenizer\n","nltk.download('punkt') \n","# Package lemmatization\n","nltk.download('wordnet')\n","# Package multilingual wordnet data\n","nltk.download('omw-1.4')"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# melakukan import dataset\n","with open('C:\\Project AI\\kelompok 7\\dataset program\\SuskaBot - FasTar\\dataset\\intents.json') as content:\n","  suskabot_dataset = json.load(content)\n","# Mendapatkan semua data ke dalam list\n","tags = [] \n","inputs = [] \n","responses = {} \n","words = []\n","classes = []\n","documents = []\n","ignore_words = ['?', '!']\n","\n","for intent in suskabot_dataset['intents']:\n","  responses[intent['tag']]=intent['responses']\n","  for lines in intent['patterns']:\n","    inputs.append(lines)\n","    tags.append(intent['tag'])\n","    for pattern in intent['patterns']:\n","      w = nltk.word_tokenize(pattern)\n","      words.extend(w)\n","      documents.append((w, intent['tag']))\n","      if intent['tag'] not in classes:\n","        classes.append(intent['tag'])\n","\n","suskabot_dataset = pd.DataFrame({\"patterns\":inputs, \"tags\":tags})"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>patterns</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>hallo</td>\n","      <td>greeting</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>hai</td>\n","      <td>greeting</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>woi</td>\n","      <td>greeting</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>wee</td>\n","      <td>greeting</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>bang</td>\n","      <td>greeting</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2134</th>\n","      <td>Nama-nama rektor UIN Suska Riau siapa saja?</td>\n","      <td>semua rektor</td>\n","    </tr>\n","    <tr>\n","      <th>2135</th>\n","      <td>Semua rektor UIN Suska Riau</td>\n","      <td>semua rektor</td>\n","    </tr>\n","    <tr>\n","      <th>2136</th>\n","      <td>Rektor UIN Suska terdahulu</td>\n","      <td>semua rektor</td>\n","    </tr>\n","    <tr>\n","      <th>2137</th>\n","      <td>Nama rektor UIN Suska Riau semua</td>\n","      <td>semua rektor</td>\n","    </tr>\n","    <tr>\n","      <th>2138</th>\n","      <td>Semua rektor UIN Suska Riau</td>\n","      <td>semua rektor</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2139 rows Ã— 2 columns</p>\n","</div>"],"text/plain":["                                         patterns          tags\n","0                                           hallo      greeting\n","1                                             hai      greeting\n","2                                             woi      greeting\n","3                                             wee      greeting\n","4                                            bang      greeting\n","...                                           ...           ...\n","2134  Nama-nama rektor UIN Suska Riau siapa saja?  semua rektor\n","2135                  Semua rektor UIN Suska Riau  semua rektor\n","2136                   Rektor UIN Suska terdahulu  semua rektor\n","2137             Nama rektor UIN Suska Riau semua  semua rektor\n","2138                  Semua rektor UIN Suska Riau  semua rektor\n","\n","[2139 rows x 2 columns]"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["# Cetak data keseluruhan\n","suskabot_dataset"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>patterns</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>hallo</td>\n","      <td>greeting</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>hai</td>\n","      <td>greeting</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>woi</td>\n","      <td>greeting</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>wee</td>\n","      <td>greeting</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>bang</td>\n","      <td>greeting</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["  patterns      tags\n","0    hallo  greeting\n","1      hai  greeting\n","2      woi  greeting\n","3      wee  greeting\n","4     bang  greeting"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["# Cetak data baris pertama sampai baris kelima\n","suskabot_dataset.head() "]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>patterns</th>\n","      <th>tags</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>2134</th>\n","      <td>Nama-nama rektor UIN Suska Riau siapa saja?</td>\n","      <td>semua rektor</td>\n","    </tr>\n","    <tr>\n","      <th>2135</th>\n","      <td>Semua rektor UIN Suska Riau</td>\n","      <td>semua rektor</td>\n","    </tr>\n","    <tr>\n","      <th>2136</th>\n","      <td>Rektor UIN Suska terdahulu</td>\n","      <td>semua rektor</td>\n","    </tr>\n","    <tr>\n","      <th>2137</th>\n","      <td>Nama rektor UIN Suska Riau semua</td>\n","      <td>semua rektor</td>\n","    </tr>\n","    <tr>\n","      <th>2138</th>\n","      <td>Semua rektor UIN Suska Riau</td>\n","      <td>semua rektor</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                         patterns          tags\n","2134  Nama-nama rektor UIN Suska Riau siapa saja?  semua rektor\n","2135                  Semua rektor UIN Suska Riau  semua rektor\n","2136                   Rektor UIN Suska terdahulu  semua rektor\n","2137             Nama rektor UIN Suska Riau semua  semua rektor\n","2138                  Semua rektor UIN Suska Riau  semua rektor"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# Cetak 5 data akhir\n","suskabot_dataset.tail() "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["DATA EXPLORATION"]},{"cell_type":"code","execution_count":25,"metadata":{},"outputs":[],"source":["#Menghilangkan Punktuasi\n","suskabot_dataset['patterns'] = suskabot_dataset['patterns'].apply(lambda wrd:[ltrs.lower() for ltrs in wrd if ltrs not in string.punctuation])\n","suskabot_dataset['patterns'] = suskabot_dataset['patterns'].apply(lambda wrd: ''.join(wrd))"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["376 unique lemmatized words [',', 'ada', 'adalah', 'aduan', 'afi', 'afternoon', 'agama', 'agama-agama', 'agroteknologi', 'aja', 'ajukan', 'ak', 'akademik', 'akademin', 'akre', 'akreditas', 'akreditasi', 'al-qur', 'alam', 'alamat', 'an', 'anak', 'anggata', 'anggota', 'apa', 'apakah', 'apasaja', 'apasih', 'aqidah', 'arab', 'arti', 'artinya', 'asdos', 'asisten', 'bagaimana', 'bagaimanakah', 'bagian', 'bahasa', 'bai', 'bang', 'banyak', 'baru', 'bayar', 'beasiswa', 'beda', 'bedanya', 'bem', 'berapa', 'berdiri', 'berdirinya', 'berita', 'biaya', 'bimbingan', 'bki', 'bot', 'bro', 'buat', 'buka', 'bye', 'byee', 'cara', 'cari', 'cat', 'cek', 'cetak', 'cuti', 'dadah', 'daftar', 'dah', 'dakwah', 'dan', 'dapat', 'dari', 'dekan', 'dema', 'dengan', 'dharma', 'di', 'diambil', 'dibentuknya', 'dibuat', 'dibuka', 'dicari', 'didirikan', 'dimaksud', 'dimana', 'dimanakah', 'dini', 'disebelah', 'dosen', 'dospem', 'dpm', 'e-journal', 'e-learning', 'ekonomi', 'eksyar', 'elearning', 'elektro', 'eskul', 'estrakulikuler', 'fakultas', 'faperta', 'fapertapet', 'fasih', 'faste', 'fdk', 'feis', 'fekon', 'fekonsos', 'filsafat', 'fpp', 'ftk', 'fungsi', 'geografi', 'gizi', 'good', 'grafik', 'guna', 'guru', 'hadis', 'hai', 'hallo', 'halo', 'he', 'hei', 'hi', 'hima', 'hk', 'htn', 'hukum', 'hy', 'ialah', 'iat', 'ibtidaiyah', 'ih', 'ilha', 'ilkom', 'ilmu', 'in', 'indonesia', 'industri', 'info', 'informasi', 'informatika', 'inggris', 'ini', 'internasional', 'ip', 'ipa', 'ipk', 'iraise', 'isi', 'islam', 'itu', 'jadwal', 'jalur', 'jelaskan', 'jumpa', 'jurnal', 'jurusan', 'kajur', 'kalender', 'kampus', 'kamu', 'kapan', 'kaprodi', 'karakteristik', 'kartu', 'kasih', 'kawan', 'ke', 'keguruan', 'keluarga', 'kepala', 'kimia', 'kip', 'kisah', 'kkn', 'komunikasi', 'konseling', 'konsentrasi', 'kr', 'ktm', 'kuliah', 'lab', 'labor', 'laboratorim', 'laboratorium', 'layanan', 'letak', 'lihat', 'lirik', 'lokasi', 'luas', 'madrasah', 'magang', 'mahasiswa', 'makalah', 'makasih', 'maksud', 'malam', 'mana', 'manajemen', 'mandiri', 'mar', 'masjid', 'masuk', 'masyarakat', 'mata', 'matematika', 'matkul', 'mazhab', 'mbkm', 'md', 'melihat', 'membuat', 'memiliki', 'mencari', 'mencetak', 'menciptakan', 'mendaftar', 'mengajukan', 'mengakses', 'mengisi', 'menjabat', 'misi', 'misii', 'morning', 'mpi', 'mpm', 'mt', 'mtk', 'nama', 'nama-nama', 'namanya', 'nasional', 'negara', 'nilai', 'ninternasional', 'organisasi', 'pada', 'pagi', 'pai', 'pasca', 'pascasarjana', 'pba', 'pekanbaru', 'pembayaran', 'pembeda', 'pembimbing', 'pembuat', 'pembuatmu', 'pencarian', 'pencipta', 'penciptamu', 'pendaftaran', 'pendidikan', 'penerimaan', 'pengajuan', 'pengembangan', 'pengerahuan', 'pengertian', 'pengetahuan', 'pengisian', 'perbandingan', 'perbankan', 'perbedaan', 'perguruan', 'peringkat', 'perpustakaan', 'persyaratan', 'pertanian', 'pertenakan', 'peternakan', 'pgmi', 'piaud', 'pintar', 'pkm', 'pm', 'pmb', 'pmi', 'portal', 'prodi', 'program', 'psikologi', 'ptkin', 'pustaka', 'rektok', 'rektor', 'riau', 'riwayat', 's2', 'saa', 'saat', 'sains', 'saintek', 'saja', 'sampai', 'sarjana', 'sarjanaapa', 'sebutan', 'sebutkan', 'see', 'sejak', 'sejarah', 'sekarang', 'selamat', 'seluruh', 'semua', 'seperti', 'si', 'siang', 'siapa', 'sih', 'sistem', 'situs', 'skripsi', 'sks', 'sore', 'sosial', 'struktur', 'studi', 'suska', 'suskabot', 'suskbot', 'syarat', 'syariah', 'tadris', 'tafsir', 'tahun', 'tarbiyah', 'tata', 'te', 'teknik', 'teknologi', 'telah', 'tempat', 'terbentuknya', 'terdahulu', 'terima', 'terimakasih', 'tersedia', 'thank', 'thanks', 'ti', 'tif', 'tinggal', 'tinggi', 'transkip', 'tri', 'tujuan', 'tutorial', 'uang', 'uin', 'ujian', 'ukm', 'ukt', 'um', 'undangan', 'ushuluddin', 'ushuludin', 'usia', 'visi', 'web', 'website', 'wee', 'wisuda', 'woi', 'yaitu', 'yang', 'yanga', 'you', 'youtube', 'yt', '}', 'â€™']\n"]}],"source":["#menghilangkan inflectional endings only dan untuk mengembalikan bentuk dictionary (kata dalam kamus) dari sebuah kata yang\n","lemmatizer = WordNetLemmatizer()\n","words = [lemmatizer.lemmatize(w.lower()) for w in words if w not in ignore_words]\n","words = sorted(list(set(words)))\n","print(len(words), \"unique lemmatized words\", words)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Menyortir Data Kelas Tags\n","classes = sorted(list(set(classes)))\n","print(len(classes), \"classes\", classes)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#Mencari Jumlah Keseluruhan Data Teks\n","print(len(documents), \"documents\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Tokenisasi Data\n","tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=2000)\n","tokenizer.fit_on_texts(suskabot_dataset['patterns'])\n","train = tokenizer.texts_to_sequences(suskabot_dataset['patterns'])\n","train"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# melakukan padding \n","X_train = tf.keras.preprocessing.sequence.pad_sequences(train)\n","print(X_train)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Encoding Label atau Tag\n","le = LabelEncoder()\n","Y_train = le.fit_transform(suskabot_dataset['tags'])\n","print(Y_train) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Input length\n","input_shape = X_train.shape[1]\n","print(\"Input Shape : \", input_shape)\n","\n","# Define vocabulary\n","vocabulary = len(tokenizer.word_index)\n","print(\"Number of unique words : \", vocabulary)\n","\n","# Output length\n","output_length = le.classes_.shape[0]\n","print(\"Output length: \", output_length)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#simpan model pemrosesan teks tersebut dengan menggunakan format pickle.\n","pickle.dump(words, open('words.pkl','wb'))\n","pickle.dump(classes, open('classes.pkl','wb'))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#simpan model pemrosesan teks tersebut dengan menggunakan format pickle.\n","pickle.dump(le, open('le.pkl','wb'))\n","pickle.dump(tokenizer, open('tokenizers.pkl','wb'))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["EVALUASI"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def suskabot_bot(trainx, trainy, neuron, batch_size, epochs):\n","    # Input Layer\n","    i = tf.keras.Input(shape=(input_shape,))\n","    x = tf.keras.layers.Embedding(vocabulary+1,10)(i) \n","    # Hidden Layer\n","    x = tf.keras.layers.LSTM(neuron, return_sequences = True)(x)\n","    x = tf.keras.layers.Dropout(0.2)(x)\n","    # Hidden Layer\n","    x = tf.keras.layers.LSTM(neuron, return_sequences = True)(x)\n","    x = tf.keras.layers.Dropout(0.2)(x)\n","    # Flatten Layer\n","    x = tf.keras.layers.Flatten()(x) \n","    # Output Layer\n","    x = tf.keras.layers.Dense(output_length, activation=\"softmax\")(x) \n","    model  = tf.keras.models.Model(i,x)\n","    # Compile model\n","    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    # Menampilkan Parameter Model\n","    print(model.summary())\n","    history = model.fit(trainx,trainy,batch_size=batch_size,epochs=epochs,verbose=1,shuffle=False)\n","    return model, history"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# LSTM Hyperparameters\n","neuron = 32\n","batch_size = 32\n","epochs = 500\n","\n","# Training the model\n","model, history_lstm = suskabot_bot(X_train, Y_train, neuron, batch_size, epochs) "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot Akurasi\n","plt.figure(figsize=(14, 5))\n","plt.subplot(1, 2, 1)\n","plt.plot(history_lstm.history['accuracy'],label='Training Set Accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Accuracy')\n","# Plot Loss\n","plt.subplot(1, 2, 2)\n","plt.plot(history_lstm.history['loss'],label='Training Set Loss')\n","plt.legend(loc='upper right')\n","plt.title('Loss')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Membuat Input Chat\n","while True:\n","  texts_p = []\n","  prediction_input = input('Kamu : ')\n","  \n","  # Menghapus punktuasi dan konversi ke huruf kecil\n","  prediction_input = [letters.lower() for letters in prediction_input if letters not in string.punctuation]\n","  prediction_input = ''.join(prediction_input)\n","  texts_p.append(prediction_input)\n","\n","  # Tokenisasi dan Padding\n","  prediction_input = tokenizer.texts_to_sequences(texts_p)\n","  prediction_input = np.array(prediction_input).reshape(-1)\n","  prediction_input = tf.keras.preprocessing.sequence.pad_sequences([prediction_input],input_shape)\n","\n","  # Mendapatkan hasil keluaran pada model \n","  output = model.predict(prediction_input, verbose=0)\n","  output = output.argmax()\n","\n","  response_tag = le.inverse_transform([output])[0]\n","  print(\"suskaBot : \", random.choice(responses[response_tag]))\n","  # tambahkan break yang berupa kata kata pada tag closing untuk mengakhiri chatbot\n","  if response_tag == \"goodbye\":\n","    break"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#melakukan save model\n","model.save('Suskabot.h5')\n","print('Model Created Successfully!')"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":0}
